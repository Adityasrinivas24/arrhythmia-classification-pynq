{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ad946-d13a-4bf6-9b39-b1a7b1cbcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_arch_list())\n",
    "\n",
    "print(f\"Is CUDA supported by this system?{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400c13c-7fb9-4687-8e16-dd24385653a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17050c3e-d358-43b5-8fa9-3dcd36b2949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f67e823b-4e59-403b-b394-52792133420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import netron\n",
    "import time\n",
    "from IPython.display import IFrame\n",
    "\n",
    "def show_netron(model_path, port):\n",
    "    time.sleep(3.)\n",
    "    netron.start(model_path, address=(\"localhost\", port), browse=False)\n",
    "    return IFrame(src=f\"http://localhost:{port}/\", width=\"100%\", height=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec34be85-1e22-4e5d-96c2-ef544e6f4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "import numpy as np\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        myWeight_bit_width = 2\n",
    "        self.features = nn.Sequential(\n",
    "            qnn.QuantIdentity(),\n",
    "\n",
    "            qnn.QuantConv2d(1, 16, kernel_size=(1, 5),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantConv2d(16, 32, kernel_size=(1, 5),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            nn.MaxPool2d(kernel_size=(1, 4), stride=(1, 4)),\n",
    "\n",
    "            qnn.QuantConv2d(32, 16, kernel_size=(1, 3),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantConv2d(16, 16, kernel_size=(1, 3),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            qnn.QuantLinear(16 * 13, num_classes, bias=True,\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e998762-0703-4d30-8521-246546f4b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"trained_models/ecgnet_w2a2_model.pth\"\n",
    "model = ECGNet()\n",
    "model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0d2fe3a-a2f4-493c-9a52-2d5da0a59f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "\n",
    "class ECGNetForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(ECGNetForExport, self).__init__()\n",
    "#         self.qnt_input = QuantIdentity(quant_type=QuantType.FP, bit_width=32)\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.qnt_output = QuantIdentity(quant_type=QuantType.INT, bit_width=8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # assume x contains bipolar {-1,1} elems\n",
    "        # shift from {-1,1} -> {0,1} since that is the\n",
    "        # input range for the trained network\n",
    "#         x = (x + torch.tensor([1.0])) / 2.0  \n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.qnt_output(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "model_for_export = ECGNetForExport(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "166f7c05-1da3-4091-aa09-dde6fed747d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.core.datatype import IntType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from  brevitas.quant_tensor import QuantTensor\n",
    "\n",
    "export_onnx_path = 'onnx_models/ecgnet_w2a2_export.onnx'\n",
    "input_shape = (1, 1, 1, 128)\n",
    "input_a = np.random.randint(0,1,size=input_shape).astype(np.float32)\n",
    "#input_a = 2*input_a - 1\n",
    "scale = 1.0\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "\n",
    "export_qonnx(model_for_export,export_path = export_onnx_path,input_t = input_t)\n",
    "qonnx_cleanup(export_onnx_path,out_file = export_onnx_path)\n",
    "\n",
    "model_for_export = ModelWrapper('onnx_models/ecgnet_w2a2_export.onnx')\n",
    "model_for_export.set_tensor_datatype(model_for_export.graph.input[0].name, DataType[\"INT8\"])\n",
    "model_for_export = model_for_export.transform(ConvertQONNXtoFINN())\n",
    "model_for_export.save(export_onnx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd5754-a50b-4da3-86bc-339d7ed535c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(export_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcd3b5cd-23b9-4fc2-8af4-79cd77e37000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.6016, -3.4684]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(input_t)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ef36e8-2491-49ca-abd0-4678c4f8357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7631, -2.5251]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.3289,  5.2307]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"datasets/last_val_data/0/101_396.npy\")\n",
    "data2 = np.load(\"datasets/last_val_data/1/118_6057.npy\")\n",
    "\n",
    "tensor_data = torch.from_numpy(data)\n",
    "tensor_data = tensor_data.unsqueeze(0)  \n",
    "tensor_data2 = torch.from_numpy(data2)\n",
    "tensor_data2 = tensor_data2.unsqueeze(0)  \n",
    "\n",
    "pred1 = model(tensor_data)\n",
    "pred2 = model(tensor_data2)\n",
    "\n",
    "print(pred1)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bc8e80e-1748-4636-a0b1-9556d52ff269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor name: global_in\n",
      "Output tensor name: global_out\n",
      "Input tensor shape: [1, 1, 1, 128]\n",
      "Output tensor shape: [1, 2]\n",
      "Input tensor datatype: INT8\n",
      "Output tensor datatype: FLOAT32\n",
      "List of node operator types in the graph: \n",
      "['MultiThreshold', 'Add', 'Mul', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'MaxPool', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'MaxPool', 'Reshape', 'MatMul', 'Mul', 'Add', 'MultiThreshold', 'Add', 'Mul']\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "model_for_sim = ModelWrapper('onnx_models/ecgnet_w2a2_export.onnx')\n",
    "finnonnx_in_tensor_name = model_for_sim.graph.input[0].name\n",
    "finnonnx_out_tensor_name = model_for_sim.graph.output[0].name\n",
    "print(\"Input tensor name: %s\" % finnonnx_in_tensor_name)\n",
    "print(\"Output tensor name: %s\" % finnonnx_out_tensor_name)\n",
    "finnonnx_model_in_shape = model_for_sim.get_tensor_shape(finnonnx_in_tensor_name)\n",
    "finnonnx_model_out_shape = model_for_sim.get_tensor_shape(finnonnx_out_tensor_name)\n",
    "print(\"Input tensor shape: %s\" % str(finnonnx_model_in_shape))\n",
    "print(\"Output tensor shape: %s\" % str(finnonnx_model_out_shape))\n",
    "finnonnx_model_in_dt = model_for_sim.get_tensor_datatype(finnonnx_in_tensor_name)\n",
    "finnonnx_model_out_dt = model_for_sim.get_tensor_datatype(finnonnx_out_tensor_name)\n",
    "print(\"Input tensor datatype: %s\" % str(finnonnx_model_in_dt.name))\n",
    "print(\"Output tensor datatype: %s\" % str(finnonnx_model_out_dt.name))\n",
    "print(\"List of node operator types in the graph: \")\n",
    "print([x.op_type for x in model_for_sim.graph.node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e09db47-ad02-49d3-afac-f52f0af04911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "model_for_sim = model_for_sim.transform(InferShapes())\n",
    "model_for_sim = model_for_sim.transform(FoldConstants())\n",
    "model_for_sim = model_for_sim.transform(GiveUniqueNodeNames())\n",
    "model_for_sim = model_for_sim.transform(GiveReadableTensorNames())\n",
    "model_for_sim = model_for_sim.transform(InferDataTypes())\n",
    "model_for_sim = model_for_sim.transform(RemoveStaticGraphInputs())\n",
    "model_for_sim = model_for_sim.transform(Change3DTo4DTensors())\n",
    "\n",
    "verif_model_filename = 'onnx_models/ecgnet_w2a2_export_verif.onnx'\n",
    "model_for_sim.save(verif_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac57a5-538e-4154-b8f7-fc482bebd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from finn.util.test import get_topk\n",
    "from finn.util.pytorch import ToTensor\n",
    "\n",
    "model = ECGNet()  \n",
    "\n",
    "input_size = (1,1,1,128)\n",
    "input_tensor_npy = np.random.randint(0,1,input_size)  \n",
    "\n",
    "input_tensor_torch = torch.from_numpy(input_tensor_npy).float()\n",
    "\n",
    "input_tensor_torch = ToTensor().forward(input_tensor_torch).detach().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  \n",
    "    output_tensor_npy = model(input_tensor_torch).numpy()\n",
    "\n",
    "output_tensor_npy  = get_topk(output_tensor_npy,k = 1)\n",
    "\n",
    "np.save('input.npy', input_tensor_npy)\n",
    "np.save('expected_output.npy', output_tensor_npy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a62c3d-dea0-4a2f-9865-0b766ebca003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6a32e-6067-4884-a298-1edd01f599ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"onnx_models/ecgnet_w2a2_export.onnx\"\n",
    "output_dir = \"output_verification_with_estimates/\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 10000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    board               = \"Pynq-Z2\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ],\n",
    "    verify_steps=[\n",
    "        build_cfg.VerificationStepType.QONNX_TO_FINN_PYTHON,\n",
    "        build_cfg.VerificationStepType.TIDY_UP_PYTHON,\n",
    "        build_cfg.VerificationStepType.STREAMLINED_PYTHON,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1006b7-4ad1-4587-9d34-ad828b1792ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
